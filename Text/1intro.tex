\section[Wstęp]{Wstęp}\label{sec:intro} %2-3 strony wprowadzenie w temat, motywacja, teza (cel)
Algorytmy Particle-in-Cell (``cząstka w komórce'') są popularną metodą
symulacji plazmy. Ich znaczącą zaletą jest mniejsza ilość koncepcyjnych
przybliżeń względem metod takich jak symulacja magnetohydrodynamiczna,
wynikająca z oparcia się o fundamentalne prawa ruchu naładowanych
cząstek i dynamicznej ewolucji pola elektromagnetycznego.

Zastosowany w nich lagranżowski opis cząsteczek pozwala na dokładne
odwzorowanie dynamiki plazmy poprzez dokonanie przybliżeń dotyczących
krótkozasięgowego ruchu elektronów i jonów. Jednocześnie, ewolucja pola
elektromagnetycznego na Eulerowskiej siatce dokonywana zamiast bezpośredniego
obliczania oddziaływań międzycząsteczkowych pozwala na znaczące przyspieszenie
etapu obliczenia oddziaływań międzycząsteczkowych. W większości symulacji
cząsteczkowych właśnie ten etap jest najbardziej krytyczny dla wydajności
progamu.\cite{birdsall}

W ostatnich czasach symulacje Particle-in-Cell zostały wykorzystane między innymi do
\begin{itemize}
\itemi{} symulacji przewidywanej turbulencji plazmy w reaktorze termojądrowym ITER~\cite{pic-turbulence}.
\itemi{} modelowania rekonekcji linii magnetycznych ~\cite{pic-reconnection}
\itemi{} projektowania silników jonowych~\cite{pic-hallengine}
\itemi{} badania interakcji laserów z plazmą w kontekście tworzenia niewielkich,
    wysokowydajnych akceleratorów cząstek~\cite{pic-laserplasma}
\end{itemize}

Należy zauważyć, że w świetle rosnącej dostępności silnie równoległej mocy
obliczeniowej w postaci kart graficznych możliwości algorytmów Particle-in-Cell
będą rosły współmiernie, co może pozwolić na rozszerzenie zakresu ich
zastosowań. Przykładem takiego projektu jest PIConGPU~\cite{picongpu}.

Inżynieria oprogramowania zorientowanego na wykorzystanie możliwości kart
graficznych, jak również w ogólności nowoczesnych symulacji wykorzystujących
dobrodziejstwa nowych technologii jest jednak utrudniona poprzez
niskopoziomowość istniejących języków klasycznie kojarzonych z symulacją
numeryczną (C, FORTRAN) oraz istniejących technologii zrównoleglania algorytmów
(MPI, CUDA, OpenCL).

Należy też zauważyć%~\cite{reproducible-science}
, że programy takie często są
trudne, jeżeli nie niemożliwe, do weryfikacji działania, ponownego wykorzystania
i modyfikacji przez osoby niezwiązane z pierwotnym autorem z powodów takich jak
\begin{itemize}
    \itemi{} brak dostępności kodu źródłowego
    \itemi{} niedostateczna dokumentacja
    \itemi{} brak jasno postawionych testów pokazujących, kiedy program działa
    zgodnie z zamiarami twórców i kiedy daje wyniki zgodne z zakładanym
    modelem fizyki realizowanych w nim zjawisk
    \itemi{} zależność działania programu od wersji zastosowanych bibliotek, sprzętu i kompilatorów
\end{itemize}

To sprawia, że pisanie złożonych programów symulacyjnych, zwłaszcza przez osoby
zajmujące się głównie pracą badawczą (na przykład w dziedzinie fizyki), bez dogłębnego, formalnego przeszkolenia
w programowaniu i informatyce, jest znacznie utrudnione.

Jest to też znacząca przeszkoda dla adaptacji
w nauce modelu \english{open science} i \english{open access} zakładanego przez Unię Europejską 
do przyjęcia jeszcze w bieżącym dziesięcioleciu, do roku 2020~\cite{euopenscience}.

Niniejsza praca ma na celu utworzenie programu symulacyjnego wykorzystującego metodę Particle-in-Cell
do symulacji oddziaływania wiązki laserowej z tarczą wodorową w popularnym języku
wysokopoziomowym Python, przy użyciu najlepszych praktyk tworzenia reprodukowalnego, otwartego oprogramowania
i zoptymalizowanie go w celu osiągania maksymalnej wydajności i sprawności obliczeniowej.

Utworzenie oprogramowania tego typu może również pozwolić na dalsze
zastosowanie programu w celach badawczych i jego dalszy rozwój, potencjalnie w
większej liczbie fizycznych wymiarów lub z użyciem kart graficznych, lub w
innych projektach.

Python został wybrany jako język służący do implementacji bieżącej symulacji
z powodu jego rosnącej popularności zarówno w programowaniu użytkowym jak i w nauce,
możliwości szybkiego prototypowania (zwłaszcza w rozbudowanych środowiskach jak
IPython~\cite{ipython} i Jupyter~\cite{jupyter}), oraz łatwość reprodukowania
warunków uruchomienia.

Atutem Pythona w wysokowydajnych obliczeniach jest łatwość użycia w nim
zewnętrznych bibliotek napisanych na przykład w C lub Fortranie, co pozwala na
osiągnięcie podobnych rezultatów wydajnościowych jak dla kodów napisanych w
językach niskopoziomowych przy minimalnej pracy z tymi językami. Istnieje
również możliwość implementacji najbardziej intensywnych obliczeniowo
fragmentów programu w językach niskopoziomowych i odwoływanie się do nich z
Pythona.

Python znajduje szerokie zastosowania w analizie danych i uczeniu maszynowym
(zwłaszcza w astronomii\cite{astropy}). W zakresie symulacji w ostatnich czasach powstały
kody skalujące się nawet w zakres superkomputerów, na przykład w mechanice
płynów.  Nie można tu nie wspomnieć o utworzonym niedawno hydrodynamicznym kodzie
PyFR, łączącym szybkie obliczenia w CUDA, OpenCL oraz OpenMP z wysokopoziomowością Pythona. Uruchomiono go na klastrze Piz Daint
i udowodniono jego skalowanie (\english{weak scaling}) do 2000 kart NVIDIA K20X i 1.3 stabilnych petaflopów na sekundę.~\cite{pyfr}~\cite{pyfr-euroscipy}

Istotną zaletą Pythona, o której nie można nie wspomnieć, jest inherentna
otwartość wśród użytkowników tego języka. Znacząca część projektów tworzonych w
tym języku jest udostępnianych za darmo jako projekty \english{open source} w
internecie na platformach takich jak GitHub, GitLab i Bitbucket, co znacząco
ułatwia kolaborację i wspólne ich tworzenie przez społeczność.  Jest to obszar,
którego techniki wydają się być równie korzystne w społeczności naukowej.


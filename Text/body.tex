\newcommand{\code}[1]{\texttt{#1}}

\section[Wstęp]{Wstęp} %2-3 strony wprowadzenie w temat, motywacja, teza (cel)
Algorytmy Particle-in-Cell (cząstka w komórce) to jedne z najbardziej zbliżonych do fundamentalnej fizyki
metod symulacji materii w stanie plazmy. Zastosowany w nich lagranżowski opis cząsteczek pozwala na dokładne
odwzorowanie dynamiki ruchu elektronów i jonów. Jednocześnie, ewolucja pola elektromagnetycznego na Eulerowskiej
siatce dokonywana zamiast bezpośredniego obliczania oddziaływań międzycząsteczkowych pozwala na znaczące
przyspieszenie etapu obliczenia oddziaływań międzycząsteczkowych. W większości symulacji cząsteczkowych właśnie
ten etap jest najbardziej krytyczny dla wydajności progamu.

W ostatnich czasach symulacje Particle-in-Cell zostały wykorzystane między innymi do
\item symulacji przewidywanej turbulencji plazmy w reaktorze termojądrowym ITER \todo{TODO: źródło, grupa Hammeta}
\item modelowania rekonekcji linii magnetycznych w polu gwiazdy \todo{TODO: źródło}
\item projektowania silników jonowych (Halla) \todo{TODO: źródło}
\item badania interakcji laserów z plazmą w kontekście tworzenia niewielkich,
    wysokowydajnych akceleratorów cząstek \todo{TODO: źródło}

    Należy zauważyć, że w świetle rosnącej dostępności silnie równoległej mocy obliczeniowej w postaci kart graficznych
    możliwości algorytmów Particle-in-Cell będą rosły współmiernie, co może pozwolić na rozszerzenie zakresu ich zastosowań.
    Przykładem takiego projektu jest PIConGPU \todo{TODO: źródło PIConGPU}

    Inżynieria oprogramowania zorientowanego na wykorzystanie możliwości kart graficznych,
    jak również w ogólności nowoczesnych symulacji wykorzystujących dobrodziejstwa nowych technologii
    jest jednak utrudniona poprzez niskopoziomowość istniejących języków klasycznie
    kojarzonych z symulacją numeryczną (C, FORTRAN) oraz istniejących technologii zrównoleglania
    algorytmów (MPI, CUDA, OpenCL).

    To sprawia, że pisanie złożonych programów symulacyjnych, zwłaszcza przez osoby
    zajmujące się głównie pracą badawczą (na przykład fizyką), a nie
    tylko programowaniem,
    jest znacznie utrudnione. Należy też zauważyć, że programy takie często są
    trudne, jeżeli nie niemożliwe do weryfikacji działania, ponownego wykorzystania
    i modyfikacji przez osoby niezwiązane z oryginalnym autorem z powodów takich jak
    \begin{itemize}
        \item brak dostępności kodu źródłowego
        \item niedostateczna dokumentacja
        \item brak jasno postawionych testów pokazujących, kiedy algorytm działa zgodnie z zamiarami twórców
        \item zależność działania kodu od wersji zastosowanych bibliotek, sprzętu i kompilatorów
    \end{itemize}

    Niniejsza praca ma na celu utworzenie kodu symulacyjnego wykorzystującego metodę Particle-in-Cell
    do symulacji oddziaływania wiązki laserowej z tarczą wodorową w popularnym języku
    wysokopoziomowym Python, przy użyciu najlepszych praktyk tworzenia reprodukowalnego, otwartego oprogramowania
    i zoptymalizowanie go w celu osiągania maksymalnej wydajności i sprawności obliczeniowej. Może to też oczywiście
    pozwolić na dalsze
    zastosowanie kodu w celach badawczych i jego dalszy rozwój, potencjalnie z użyciem kart graficznych.
    Ostatecznie, jest to również test wydajnościowy możliwości Pythona w symulacjach \todo{Zamiast ostatecznie chciałbym
    dać coś typu last but not least}
    numerycznych.

\section[Część analityczno-teoretyczna]{Część analityczno-teoretyczna} % 30% pracy - opis problematyki podjętego tematu w zakresie wykorzystanym w pracy i analizie

    \subsection{Plazma - czwarty stan materii}

    Plazma, powszechnie nazywana czwartym stanem materii, to zbiór zjonizowanych
    cząstek oraz elektronów przejawiających jako grupa globalną obojętność elektryczną. Innymi słowy, od gazu plazmy
    odróżnia fakt, że cząstki są zjonizowane, więc oddziałują kolektywnie między sobą na odległość,
    ale ich pola elektryczne wzajemnie się neutralizują na długich dystansach.

    Plazmy występują w całym wszechświecie, od materii międzygwiezdnej po błyskawice.
    Ich istnienie uwarunkowane jest obecnością wysokich energii, wystarczających do zjonizowania atomów gazu.

    Fizyka plazmy jest stosunkowo młodą nauką, której rozwój nastąpił dopiero w ostatnim stuleciu, zaczynając od badań
    Langmuira (1928), który eksperymentował z jonizowaniem gazów w szklanych rurach zwanych rurami Crookesa. \todo{TODO reference}
    
    Globalny wzrost zainteresowania fizyką plazmy na arenie geopoliycznej ozpoczął się w latach '50 ubiegłego wieku, \todo{TODO - zweryfikować}
    gdy uświadomiono sobie, że można zastosować ją do przeprowadzania kontrolowanych reakcji syntezy jądrowej, \todo{TODO: reference: fusion in europe history of fusion}
    które mogą mieć zastosowania w energetyce jako następny etap rozwoju po reakcjach rozpadu wykorzystywanych
    w "klasycznych" elektrowniach jądrowych. Był to jeden z elementów zimnowojennego wyścigu technologicznego
    międzu Stanami Zjednoczonymi a ZSRR, \todo{TODO reference}
    jak również jeden z projektów mających na celu ponowne nawiązanie współpracy naukowej między supermocarstwami
    po zakończeniu tego konfliktu. \todo{TODO reference fusion for energy history of fusion}

    Poza tym ogromnym projektem plazmy mają szerokie zastosowania w obecnym przemyśle, na przykład:
    \begin{itemize}
        \item metalurgicznym - przecinaki plazmowe \todo{TODO: sprawdzić nazwę - łukowe coś?}
        \item elektronicznym - nacinanie powierzchni urządzeń półprzewodnikowych \todo{TODO: przeformułować}
        \item materiałowym - powierzchniowa obróbka materiałów, \todo{TODO ref}
            CVD \todo{TODO ref}
        \item kosmicznym - silniki plazmowe, interakcja z rozgrzanym powietrzem podczas powtórnego wchodzenia 
            w atmosferę \todo{TODO: to potrzebuje źródła}
        \item użytkowym - ekrany telewizorów, oświetlenie (świetlówki)
        \item utylizacja odpadów \todo{TODO ref}
        \item czyszczenie powierzchni \todo{TODO ref}
            \todo{TODO coś jeszcze?}
    \end{itemize}

    Należy też zwrócić uwagę, że ze względu na złożoność układów plazmowych pre-komputerowa fizyka miała ogromne
    problemy z merytorycznymi badaniami zachowania plazmy poza wybranymi, mocno uproszczonymi reżimami. Postęp w badaniach
    plazmy, jak sugeruje rozwój technologii kontrolowanej syntezy jądrowej,
    jest silnie skorelowany \todo{ref youtube wykład}
    z rozwojem mocy obliczeniowej oraz algorytmów symulacyjnych.

    \subsection{Modelowanie i symulacja plazmy}

    Zjawiska z zakresu fizyki plazmy są jednymi z bardziej złożonych problemów modelowanie komputerowej.
    Głównym, koncepcyjnie, powodem uniemożliwiającym zastosowanie prostych metod symulacji
    znanych z newtonowskiej dynamiki molekularnej jest mnogość oddziaływań - każda cząstka oddziałowuje
    z każdą inną nawzajem poprzez niepomijalne oddziaływania kulombowskie, skalujące się z odległością jak
    $\approx r^{-2}$.

    Z powodu dużej liczby cząstek w układach plazmowych, jedynymi praktycznymi podejściami fundamentalnymi
    (jako opierającymi się na fundamentalnej fizyce) \todo{styl?}
    są opisy statystyczne,
    opierające się na modelach kinetycznych. Wielkością opisującą plazmę jest tu funkcja dystrybucji zdefiniowana jako
    \todo{dodać reference na opis statystyczny}
    \begin{equation}
        \int \int f(\vec{x}, \vec{v}, t) d\vec{x} d\vec{v} = 1
        \label{eqn:distribution-function}
    \end{equation}

        \todo{napisać wzór; Normalizacja?}
    opisująca gęstość prawdopodobieństwa rozkładu plazmy w N-sześciowymiarowej przestrzeni fazowej (po trzy wymiary na położenia
    oraz prędkości, powielone dla każdej z N cząstek).

    \todo{poczytać o tym żeby mieć sposób na przejście}
    Podstawowym równaniem statystycznym opisującym plazmę jest równanie Vlasova \todo{może zacząć od Klimontowicza, jest wyprowadzalne z niego}

    \begin{equation}
        \frac{d} {dt} f_{\alpha} (\vec{x}, \vec{v}, t) - \nabla f - \nabla_{\vec{v}} (\vec{v} \times \vec{B} + \vec{E})= f_{coll}
        \label{eqn:Vlasov}
    \end{equation}
        \todo{wzór na równanie Vlasova}

    W praktyce jest ono również nierozwiązywalne poza trywialnymi przypadkami o ułatwiających problem symetriach.
    Jednym z powodów jest koniecznośc uzyskania dobrej rozdzielczości prędkości
    przy jednoczesnym zachowaniu zakresów obejmujących prędkości relatywistyczne. Należy zauważyć, że skalowanie
    liczby punktów na siatce tego typu jest proporcjonalne do $N_r^3 N_v^3$, gdzie $N_r$ to liczba punktów przestrzennych, zaś
    $N_v$ to liczba punktów na siatce prędkości. Jest to więc niepraktyczne
    obliczeniowo, \todo{przeformułować}
    między innymi ze względu na istotne w plazmach zjawisko ``uciekających elektronów'' o dużych prędkościach.
    \todo{runaway electrons - przeformułować}
    \todo{zweryfikować słabości lattice boltzmann}

    W modelowaniu komputerowym plazmy stosuje się dwa główne podejścia:
    \begin{enumerate}
        \item modele kinetyczne \todo{do napisania}
        \item modele płynowe oparte na ciągłym opisie plazmy poprzez uśrednienie po dystrybucji
            wielkości termodynamicznych, co daje modele takie jak magnetohydrodynamikę \todo{reformulate}
        \item modele dyskretne oparte na samplowaniu dystrybucji plazmy przy użyciu dyskretnych cząstek
            (matematycznie jest to równanie Klimontowicza przybliżające równanie Vlasova) \todo{read about this}
    \end{enumerate}

    Prawdopodobnie najpopoularniejszym modelem z tej drugiej kategorii są modele Particle-in-cell.

    \section{Modele Particle-in-cell}

    Idea modelu particle-in-cell jest wyjątkowo prosta i opiera się na idei przyspieszenia najbardziej złożonego obliczeniowo kroku
    symulacji dynamiki molekularnej, czyli obliczania sił międzycząsteczkowych. Cząstki poruszają się w ciągłej, Lagrange'owskiej przestrzeni.
    Ich ruch wykorzystywany jest do zebrania informacji dotyczącej gęstości ładunku i prądu na dyskretną, Eulerowską siatkę. Na siatce rozwiązane
    są (jako równania różniczkowe cząstkowe) równania Maxwella, dzięki którym otrzymuje się pola elektryczne i magnetyczne, które z powrotem są przekazane
    do położeń cząstek. Obliczeniowo, uwzględniając koszty odpowiednich interpolacji, pozwala to zredukować złożoność kroku obliczenia sił międzycząsteczkowych
    do $n \log{n}$ z $n^2$ \todo{wyrazić złożoność PIC przez rozmiar siatki}

    \subsection{Pętla obliczeniowa PIC}
    Algorytm particle-in-cell składa się z czterech elementów \todo{GRAFIKA: cykliczny schemacik}
    \subsubsection{GATHER}
    Depozycja ładunku oraz prądu z położeń cząstek do lokacji na dyskretnej siatce poprzez interpolację,
    co pozwala na sprawne rozwiązanie na tej siatce
    równań Maxwella jako układu różnicowych równań cząstkowych zamiast obliczania skalujących się kwadratowo w liczbie cząstek
    oddziaływań kulombowskich między nimi.
    W naszym elektromagnetycznym przypadku bardziej istotną jest depozycja prądu na siatkę, co szerzej tłumaczy następny
    fragment. \todo{słowo fragment}
    \subsubsection{SOLVE}
    Sprawne rozwiązanie równań Maxwella na dyskretnej, Eulerowskiej siatce.
    Znalezienie pól elektrycznego i magnetycznego
    na podstawie gęstości ładunku i prądu na siatce.
    Istnieją dwie główne szkoły rozwiązywania tych równań: metody globalne i lokalne. Metody globalne wykorzystują
    zazwyczaj równania dywergencyjne (prawo Gaussa)
    \begin{equation}
        \rho / \varepsilon_0 = \nabla \cdot \vec{E}
        \label{poisson-eq}    
    \end{equation}
    rozwiązywane iteracyjnie (metody takie jak Gaussa-Seidela)
    lub spektralnie.
    Metody lokalne z kolei wykorzystują równania rotacyjne (prawo Ampera) \todo{nie Faradaya?}
    \begin{equation}
        \partial \vec{E} / \partial t = \mu_0(\nabla \times \vec{B} + \vec{j})
        \label{FIXME}
    \end{equation}
    \todo{poprawić równanko}

    Metody globalne nadają się do modeli elektrostatycznych, nierelatywistycznych. 
    Metody lokalne pozwalają na ograniczenie szybkości propagacji zaburzeń do prędkości światła, co przybliża
    metodę numeryczną do fizyki zachodzącej w rzeczywistym układzie tego typu.
    \subsubsection{SCATTER}
    Interpolacja pól z siatki do lokacji cząstek, co pozwala określić siły elektromagnetyczne działające na cząstki.
    Należy przy tym zauważyć, że jako że interpolacja sił wymaga jedynie lokalnej informacji co do pól
    elektromagnetycznych w okolicy cząstki, ta część algorytmu sprawia, że algorytmy Particle-in-cell doskonale
    nadają się do zrównoleglania (problem jest w bardzo dobrym przybliżeniu ``trywialnie paralelizowalny''). Z tego powodu algorytmy
    Particle-in-cell nadają się doskonale do wykorzystania rosnącej mocy kart graficznych i architektur GPGPU.
    \subsubsection{PUSH}
    iteracja równań ruchu cząstek
    \begin{equation}
        d \vec{p}/dt = \vec{F} = q (\vec{E} + \vec{v} \times \vec{B}
        \label{eq-of-motion}
    \end{equation}
    
    na podstawie ich prędkości (aktualizacja położeń)
    oraz działających na nie sił elektromagnetycznych (aktualizacja prędkości). Należy zauważyć, że modele PIC
    nie modelują bezpośrednich kolizji między cząstkami - mogą one jednak zostać dodane niebezpośrednio, na przykład
    poprzez metody Monte Carlo. \todo{refka}

    Jako że każda cząstka, zakładając znane pola elektromagnetyczne w jej położeniu, porusza się niezależnie,
    jest to kolejny fragment doskonale nadający się do zrównoleglenia.

    \subsection{Makrocząstki}
    Należy zauważyć, że obecnie nie jest możliwe dokładne odwzorowanie dynamiki układów plazmowych w sensie interakcji
    między poszczególnymi cząstkami ze względu na liczbę cząstek rzędu liczby Avogadro $\approx 10^{23}$.
    W tym kontekście bardzo szczęśliwym jest fakt, że wszystkie istotne wielkości zależą nie od ładunku ani masy,
    ale od stosunku $q/m$. W praktyce stosuje się więc \emph{makrocząstki}, obdarzone ładunkiem i masą będące wielokrotnościami
    tych wielkości dla cząstek występujących w naturze (jak jony i elektrony, pozwalając jednocześnie zachować gęstości
    cząstek i ładunku \todo{oraz inne wielkości fizyczne)}
    zbliżone do rzeczywistych.

    W symulacjach elektromagnetycznych zazwyczaj (``tradycyjnie'') stosuje się gęstości cząstek (rzeczywistych)
    rzędu jednej dziesiątej bądź setnej gęstości
    krytycznej plazmy $n_c$, która oznacza taką koncentrację elektronów, przy której \todo{zweryfikować}
    fala laserowa zostaje całkowicie wytłumiona i nie propaguje się dalej przez plazmę.

    \begin{equation}
        n_c = m_e \varepsilon_0 * (\frac{2 \pi c}{e \lambda})^2
        \label{eqn:critical-density}
    \end{equation}
    gdzie $m_e$ to masa spoczynkowa elektronu, $\varepsilon_0$ to przenikalność elektryczna próżni, \todo{przenikalność?}
    $c$ to prędkość światła w próżni, $e$ to ładunek elementarny, zaś $\lambda$ to długość fali.

    Gęstość takiej makrocząstki, oznaczana $n_{pic}$, oznacza innymi słowy liczbę rzeczywistych cząstek, jakie reprezentuje
    sobą jedna makroczątka. \todo[inline]{To jest generalnie moja własna analiza i nie jestem jej w 100% pewien, ale tak
    80% to dałbym.}

    \subsection{Problem testowy}

    Problemem testowym, jakiego używamy do przetestowania dokładności i wydajności działania algorytmu jest
    interakcja impulsu laserowego z tarczą składającą się ze zjonizowanego wodoru i elektronów.

    Układ ten modelowany jest jako jednowymiarowy. Jest to tak zwany w literaturze model 1D-3D.
    O ile położenia cząstek są jednowymiarowe ze względu na znaczną symetrię
    cylindryczną układu, cząstki mają prędkości w pełnych trzech wymiarach. Jest to konieczne ze względu
    na oddziaływania cząstek z polem elektromagnetycznym propagującym się wzdłuż osi układu.

    Układ ten jest silnie zbliżony do rzeczywistych eksperymentów prowadzonych w IFPiLM.
    \todo[inline]{Tu bym chciał prosić o weryfikację.}

    \subsection{Python}
    Python jest wysokopoziomowym, interpretowanym językiem programowania, którego atutami są szybkie prototypowanie,

    Python znajduje zastosowania w analizie danych, uczeniu maszynowym (zwłaszcza w astronomii). W zakresie symulacji
    w ostatnich czasach powstały kody skalujące się nawet w zakres superkomputerów, na przykład w mechanice płynów.
    Nie można tu nie wspomnieć o utworzonym ostatnio kodzie \code{PyFR},
    \todo{refka i opis PyFR}

    Atutem Pythona w wysokowydajnych obliczeniach jest łatwość wywoływania w nim zewnętrznych bibliotek napisanych
    na przykład w C lub Fortranie, co pozwala na osiągnięcie podobnych rezultatów wydajnościowych jak dla kodów
    napisanych w językach niskopoziomowych bez faktycznej pracy z tymi językami. Ostatnimi czasy popularną staje się
    również kompilacja just-in-time wysokopoziomowego kodu Pythona do kodu niskopoziomowego przy pierwszym
    uruchomieniu programu \todo{numba}


\section[Implementacja]{Implementacja}% 20-30% - opis przyjętych rozwiązań i uzasadnienie ich wyboru
    \subsection{Zastosowane algorytmy}
    \subsubsection{Leapfrog oraz Borys}
    Każda symulacja cząstek wymaga zastosowania integratora równań ruchu. Tradycyjnym przykładem takiego
    integratora jest integrator Rungego-Kutty czwartego rzędu, znajdujący zastosowanie w wielorakich
    symulacjach. \todo{reference}

    Niestety, w bieżącym kodzie nie można go zastosować ze względu na jego niesymplektyczność:
    mimo ogromnej dokładności jest on niestabilny pod względem energii cząstek. \todo{reference}
    W symulacjach typu Particle-in-cell konieczne jest zastosowanie innych algorytmów. Dobrym algorytmem
    symplektycznym jest na przykład powszechnie znany \emph{leapfrog}, polegający na
    przesunięciu prędkości o połowę iteracji czasowej względem położeń.\todo{reference}
    Mimo tego, że energie cząstek w ruchu obliczonym tym integratorem nie są lokalnie stałe na krótkich skalach
    czasowych, to jednak zachowują energię na skali globalnej.

    \todo{IMAGE: chyba miałem to na coldplasma}

    W przypadku ruchu w polu magnetycznym nie wystarczy, niestety, użyć zwykłego algorytmu \emph{leapfrog}. \todo{READ}
    Używa się tutaj specjalnej adaptacji tego algorytmu na potrzeby ruchu w zmiennym polu elektromagnetycznym,
    tak zwanego integratora Borysa, \todo{REFERENCE}
    który rozbija pole elektryczne na dwa impulsy, między którymi następują dwie \todo{CHECK}
    rotacje polem magnetycznym. Algorytm jest dzięki temu symplektyczny
    i długofalowo zachowuje energię cząstek.
    
    \begin{equation}
        bo = ris
        \label{eqn:boris-pusher}
    \end{equation}
 \todo{boris pusher equation}
    W naszym przypadku dochodzi jeszcze jedno utrudnienie związane z relatywistycznością symulacji. \todo{stylistyka}
    Przed obliczeniem korekty prędkości konieczne jest przetransformowanie prędkości z układu ``laboratoryjnego'' $\vec{v}$
    na prędkość w układzie poruszającym się z cząstką $\vec{u}$, czego dokonuje się poprzez parę transformacji:

    \begin{align}
        \vec{u} = \vec{v} \gamma
        \label{eqn:gamma-transformation}
    \end{align}
 \todo{finish this eq}
    \subsubsection{Depozycja gęstości ładunku i prądu} \todo{pick up here}
    Depozycja ładunku odbywa się w prosty sposób, przy następujących założeniach:
    \begin{itemize}
        \item Każda makrocząstka ma własny (wspólny wewnątrz \code{Species}) ładunek $q$ oraz parametr \code{scaling} (również) \todo{STYLE?}
            decydujący o tym, ile rzeczywistych cząstek reprezentuje. Sumaryczny ładunek makrocząstki wynosi więc \code{q*scaling}
        \item Każda makrocząstka ma szerokość jednej komórki siatki $\Delta x$. Cząstka zlokalizowana więc środkiem
            w połowie długości komórki będzie w niej całkowicie zawarata.
        \item W ten sposób możemy stwierdzić, \todo{CONTINUE}
    \end{itemize}

    Powszechnie stosowana od zarania dziejów metod particle-in-cell \todo{refka: Dawson}
    jest interpolacja liniowa, polegająca na zdepozytowaniu w $i$-tej komórce siatki \todo{dokończyć}

    $1 = \sum_i S_i$ \todo{dokończyć wzór}

    W naszym przypadku wymagamy również, żeby depozycja prądu była spójna z depozycją ładunku, to znaczy
    zachowywała ładunek. 

    \subsubsection{Interpolacja pól elektrycznego i magnetycznego}
    Interpolacja pól elektrycznego i magnetycznego odbywa się na bardzo podobnej zasadzie, co depozycja.
    Wartosci pol sa liniowo skalowane do pozycji czastek wedlug ich wzglednych położeń wewnątrz komórek.

    W celu przyśpieszenia działania programu stosuje się istniejącą metodę
    \code{RegularGridInterpolator} z biblioteki \code{scipy.interpolate}. \todo{zaimplementować i sprawdzić}
    \todo{CONTINUE opowiadanie o interpolacji}
    \subsubsection{Field solver} \todo{przerobić}

    Ewolucja pola elektromagnetycznego opisana jest poprzez równania Maxwella. Jak pokazują Buneman i Villasenor,
    numerycznie można zastosować dwa główne podejścia: \todo{zredagować}
    1. wykorzystać równania na dywergencję pola (prawa Gaussa) do rozwiązania pola na całej siatce. Niestety, jest to
    algorytm inherentnie globalny, w którym informacja o warunkach brzegowych jest konieczna w każdym oczku siatki
    \todo{alternatywa na słowo "oczko"?}
    2. wykorzystać równania na rotację pola (prawa Ampera i Faradaya), opisujące ewolucję czasową pól. Jak łatwo pokazać (Buneman),
    dywergencja pola elektrycznego oraz magnetycznego nie zmienia się w czasie pod wpływem tak opisanej ewolucji czasowej:

    Co za tym idzie, jeżeli rozpoczniemy symulację od znalezienia pola na podstawie warunków brzegowych i początkowych (gęstości
    ładunku), możemy już dalej iterować pole na podstawie równań rotacji. Ma to dwie znaczące zalety:
    * algorytm ewolucji pola staje się trywialny obliczeniowo, zwłaszcza w 1D -
        ogranicza się bowiem do elementarnych operacji lokalnego dodawania i mnożenia.
    * algorytm ewolucji pola staje się lokalny (do znalezienia wartości pola w danym oczku w kolejnej iteracji wykorzystujemy
    jedynie informacje zawarte w tym właśnie oczku i potencjalnie jego sąsiadach \todo{jak to faktycznie wygląda z tym algo?}
    co zapobiega problemowi informacji przebiegającej w symulacji szybciej niż światło oraz zapewnia stabilność na podstawie
    warunku Couranta.

    \todo{gładsze przejście tutaj - wyprowadzenie field solvera}
    W 1D można dokonać dekompozycji składowych poprzecznych pola elektromagnetycznego (tutaj oznaczanych $y$, $z$) na
    propagujące się w przód ($+$) i w tył ($-$) obszaru symulacji. Składowe $E_y$, $B_z$ są zebrane poprzez zamianę zmiennych
    w dwie wielkości elektrodynamiczne $F^+$, $F^-$.

    Wychodzimy z rotacyjnych równań Maxwella:

    \begin{equation}
        \nabla \times \vec{E} = -\frac{\partial \vec{B}}{\partial t}
        \nabla \times \vec{B} = \mu_0 (\vec{j} + \epsilon_0 \frac{\partial \vec{E}}{\partial t})
        \label{eqn:Maxwell-rotation-derivation}
    \end{equation}

    \todo{skończyć wyprowadzenie}

    \begin{equation}
        F^{+} = E_y + c B_z
        F^{-} = E_y - c B_z
        \label{eqn:Birdsall-electromagnetic-quantities}
    \end{equation}
    Analogicznie, dla składowych $E_z$, $B_y$:

    \todo{zweryfikować znaki i czy c nie jest w mianowniku}
    \begin{equation}
        G^{+} = E_z - c B_y
        G^{-} = E_z + c B_y
        \label{eqn:Birdsall-electromagnetic-quantities-alternate-axes}
    \end{equation}
    Wyrazem ``źródłowym'' dla F, G jest prąd poprzeczny. Po dyskretyzacji równania, wyrażenie na ewolucję pól F, G między
    iteracjami przybiera postać:

    \begin{equation}
        {F^{+}}^{n+1}_{i+1} = F^{+}_{n} + j
    \end{equation}
\todo{sprawdzić}
    Z tego powodu bardzo istotnym dla dokładności i stabilności algorytmu staje się sposób depozycji ładunku - należy pilnować,
    aby był robiony w sposób który spełnia zachowanie ładunku. Inaczej koniecznym staje się aplikowanie tak zwanej
    poprawki Borysa, \todo{źródło - prezentacja}
    aby upewnić się, że warunek z równań Maxwella $\nabla \rho / \varepsilon_0 = \nabla \cdot \vec{E}$ jest
    wciąż spełniony.

    Składowa podłużna pola jest obliczana poprzez wyrażenie

    \begin{equation}
    \frac{\partial E_x}{\partial t} = - \frac{j_x}{\varepsilon_0}
    \label{longitudinal-field-differential}
    \end{equation}

    czy raczej jej dyskretny odpowiednik

    \begin{equation}
        E_i^{n+1} = E_i^n - \frac{\Delta t}{\varepsilon_0} j_{x,i}^{n+1/2}
    \label{longitudinal-field-finite-differential}
    \end{equation}


    \subsection{Warunki początkowe dla cząstek}

    W celu dobrania warunków początkowych wykorzystuje się algorytm opisany w .\todo{Birdsall Langdon}
    Jego działanie można łatwo zilustrować na przykładzie początkowej funkcji gęstości cząstek zadanej
    dowolną funkcją analityczną. \todo{czy analityczna nie jest słowem zarezerwowanych dla tych na szeregi}
    Używając funkcji dystrybucji w jednym wymiarze zależnej jedynie od położenia znormalizowanej do
    liczby cząstek $N$, można wykonać całkowanie kumulatywne po siatce gęstszej niż liczba cząstek
    na wybranym przedziale, po czym umieścić cząstki w miejscach, gdzie obliczona dystrybuanta funkcji
    przybiera kolejne większe całkowite wartości.

    \todo{rysunek: przykład z ipynb}

    Zaimplementowany algorytm jest w stanie przyjąć dowolną funkcję analityczną \todo{czy nie przesadzam?}
    i zrenormalizować ją tak, aby $\int_0^L f(x) dx = N$. W praktyce wykorzystuje się wartości marginalnie większe
    niż $N$, mianowicie $N+0.1$, co pozwala na uniknięcie problemów ze skończoną dokładnością obliczeń
    na liczbach zmiennoprzecinkowych.

    Aby uniknąć problemu w przypadku dwóch \code{Species} cząstek o identycznej liczbie makrocząstek i przeciwnym znaku
    które według powyższego algorytmu zostałyby rozłożone w identycznych miejscach z powodu niezależnego
    stosowania algorytmu dla każdej grupy cząstek, co prowadziłoby do neutralizacji ładunku na całej symulacji,
    na położenia cząstek nakłada się dodatkowy gaussowski szum o niewielkiej intensywności.

    Analogiczny algorytm znajduje zastosowanie w obliczaniu początkowych wartości prędkości dla cząstek.
    Wykorzystuje się relatywistyczny rozkład Maxwella

    \begin{align}
        f(p) = \frac{N}{2 \pi} \frac{mc^2}{T} \frac{1}{1+T/mc^2} \exp \Big (\frac{-mc^2}{T}(\gamma -1) \Big)
        \gamma = \sqrt{1+p^2}
        \label{relativistic-maxwell-distribution}
    \end{align}

    Należy wspomnieć, że aby cząstki były prawidłowo ztermalizowane \todo{czy to jest słowo}
    należy zadbać o zdekorelowanie ich prędkości między sobą. Naiwne zastosowanie algorytmu na położenia
    prowadzi zaś do rozłożenia cząstek rosnąco numeracją w kierunku rosnącego położenia $x$.

    Rozwiązaniem tego problemu jest losowa zamiana prędkości między losowo wybranymi cząstkami.
    \todo{dopisać jak będzie zrobione.}

    \subsection{Opis i treść kodu}
    Cały kod programu w celu reprodukowalności wyników tworzony był i jest dostępny na platformie Github \todo{link}

    \subsection{Wykorzystane biblioteki i technologie}

    \subsubsection{Numpy}
    \code{numpy} to biblioteka umożliwiająca wykonywanie złożonych obliczeń na n-wymiarowych macierzach
    bądź tablicach, utworzona w celu umożlwiienia zastąpienia operacjami wektorowymi iteracji po tablicach,
    powszechnie stosowanych w metodach numerycznych i będących znanym słabym punktem Pythona.
    \todo{REFERENCE źródło na powolność pętli}

    Pod zewnętrzną powłoką zawiera odwołania do
    znanych, wypróbowanych i sprawdzonych w numeryce modułów \code{LAPACK}, \code{BLAS}
    napisanych w szybkich, niskopoziomowych językach C oraz \code{FORTRAN}.
    Jest to \emph{de facto}
    standard większości obliczeń numerycznych w Pythonie.

    Należy zauważyć, że operacje matematyczne w \code{Numpy} są automatycznie zrównoleglane \todo{refka intel MKL}
    tam, gdzie pozwala na to niezależność obliczeń.

    Numpy jest oprogramowaniem otwartym, udostępnianym na licencji BSD. \todo{refka}

    \subsubsection{scipy}
    Kolejną podstawową biblioteką w numerycznym Pythonie jest \code{scipy}, biblioteka
    zawierająca wydajne implementacje wielu podstawowych algorytmów numerycznych służących
    między innymi całkowaniu, optymalizacji, algebrze liniowej czy transformatom Fouriera.
    W naszym przypadku stosujemy zawarte w tej bibliotece funkcje całkujące do określenia
    początkowego profilu gęstości plazmy.
    \todo{czy stosuję scipy gdzieś jeszcze}

    \subsubsection{Numba}
    \code{numba} to biblioteka służąca do kompilacji just-in-time kodu.
    \todo{Przerobić wyjaśnienie działania Numba}
    W wielu przypadkach
    pozwala na osiągnięcie kodem napisanym w czystym Pythonie wydajności marginalnie
    niższej bądź nawet równej do analogicznego programu w C bądź Fortranie. \todo{refka}
    Jednocześnie należy zaznaczyć prostotę jej użycia:

    \todo{fragment kodu. @jit przed kodem}


    \subsubsection{HDF5}
    HDF5 jest wysokowydajnym formatem plikow służącym przechowywaniu danych liczbowych w drzewiastej,
    skompresowanej strukturze danych, razem z równoległym, wielowątkowym zapisem tych danych.
    W Pythonie implementuje go biblioteka h5py. \todo{reference h5py}
    Używa się go na przykład w \todo{lista miejsc gdzie używają hdf5}
    \todo{https://github.com/PPPLDeepLearning/plasma-python}

    W bieżącej pracy wykorzystuje się go do przechowywania danych numerycznych dotyczących
    przebiegu symulacji, pozwalających na ich dalsze przetwarzanie i analizę poprzez
    wizualizację.

    \subsubsection{matplotlib}
    Do wizualizacji danych z symulacji
    (oraz tworzenia schematów w sekcji teoretycznej niniejszej pracy)
    użyto własnoręcznie napisanych skryptów w uniwersalnej bibliotece graficznej
    \code{matplotlib}. \code{matplotlib} zapewnie wsparcia zarówno
    dla grafik statycznych w różnych układach współrzędnych (w tym 3D), jak również dla
    dynamicznie generowanych animacji przedstawiających przebiegi czasowe symulacji.

    Matplotlib również jest oprogramowaniem otwartym, udostępnianym na licencji
    \todo{matplotlib license, reference}

    \subsubsection{py.test}
    Przy pracy nad kodem użyto frameworku testowego \code{py.test} \todo{refenrece}
    Obsługa testów jest trywialna:

    \todo{przykład testu z programu}

    Należy zaznaczyć, że w numeryce, gdzie błędne działanie programu nie objawia się
    zazwyczaj błędem wykonywania programu, a jedynie błędnymi wynikami, dobrze zautomatyzowane
    testy jednostkowe potrafią zaoszczędzić bardzo dużo czasu na debugowaniu
    poprzez automatyzację uruchamiania kolejnych partii kodu i lokalizację błędnie działających
    części algorytmu. Dobrze napisane testy są praktycznie koniecznością w dzisiejszych
    czasach, zaś każdy nowo powstały projekt numeryczno-symulacyjny powinien je
    wykorzystywać, najlepiej do weryfikacji każdej części algorytmu z osobna.

    Dobrym przykładem skutecznego testu jednostkowego jest porównanie wyników z fragmentu
    algorytmu (na przykład depozycji ładunku, który to test zawarty jest w pliku)
    \code{pythonpic/tests/test\_current\_deposition.py} \todo{sprawdzić urla}
    z wynikami z poprzedniego, zweryfikowanego programu, bądź z obliczeniem ręcznym.

    \code{py.test} jest oprogramowaniem otwartym, dostępnym na licencji \todo{sprawdzić licencję}

    \subsubsection{Travis CI}
    Nieocenionym narzędziem w pracy nad kodem był system ciągłej integracji (\emph{continuous integration})
    Travis CI \todo{refka}
    dostępny za darmo dla projektów open-source. Travis pobiera aktualne wersje kodu przy każdej aktualizacji
    wersji dostępnej na serwerze GitHub i uruchamia testy, zwracając komunikat o ewentualnym niepowodzeniu i
    pozwalając na jednoczesne uruchamianie bieżących, intensywnych symulacji przy jednoczesnym uruchamianiu
    lżejszych, acz wciąż zasobożernych \todo[inline]{to słowo}
    symulacji testowych i testów algorytmicznych.

    \subsection{snakeviz}
    W optymalizacji przydatny okazał się program \code{snakeviz} dostępny na licencji opensource i pozwalający na
    wizualizację wyników z profilowania symulacji. Pozwala w wygodny sposób zbadać, które fragmenty kodu najbardziej
    spowalniają symulację, które są najlepszymi kandydatami do optymalizacji, oraz jak skuteczne (bądź nieskuteczne)
    okazują się próby polepszenia ich wydajności.
    \todo{refka}
    \todo{grafika snakeviz}

    \subsection{Struktura i hierarchia kodu}

    Program ma obiektową strukturę zewnętrzną, którą w celu łatwości zrozumienia jego działania nakrywa wewnętrzną warstwę
    składającą się głównie z n-wymiarowych tablic \code{numpy.ndarray} oraz zwektoryzowanych operacji na nich.

    Część symulacyjna kodu składa się z kilku prostych koncepcyjnie elementów:

    \subsubsection{Grid}
    Klasa reprezentująca dyskretną siatkę Eulera, na której dokonywane są obliczenia dotyczące
    pól elektromagnetycznych oraz gęstości ładunku i prądu.
    Zawiera:
    \begin{itemize}
        \item $x_i$ - tablicę położeń lewych krawędzi komórek siatki
        \item $N_G$ - liczbę komórek siatki
        \item $T$ - sumaryczny czas trwania symulacji
        \item $\Delta x$ - krok przestrzenny siatki - $N_G * \Delta x$ daje długość obszaru symulacji
        \item $\rho_i$ - tablicę gęstości ładunku na siatce.
        \item $\vec{j}_{i,j}$ - tablicę gęstości prądu na siatce.
        \item $E_{i,j}$ - tablicę pola elektrycznego na siatce.
        \item $B_{i,j}$ - tablicę pola magnetycznego na siatce.
        \item $c$, $\varepsilon_0$ - stałe fizyczne - prędkość światła oraz przenikalność elektryczną próżni.
        \item $\Delta t$ - krok czasowy symulacji, obliczony jako $\Delta t = \Delta x / c$.
        \item $N_T$ - liczbę iteracji czasowych symulacji.
        \item \code{BC} - \emph{Boundary Condition}, funkcję czasu określającą wartość warunku brzegowego dotyczącego
            natężenia fali elektromagnetycznej (laserowej) wchodzącej do pola symulacji z lewej strony.
    \end{itemize}

    Istotne metody klasy \code{Grid}, o których należy wspomnieć, to:
    \begin{itemize}
         \item \code{apply\_bc} - aktualizuje krańcowe wartości tablic $E$, $B$ w oparciu o podany warunek brzegowy.
         \item gather\_current \todo{finish these}
         \item gather\_charge
         \item solve
         \item field\_solve
         \item electric\_field\_function, magnetic
         \item save\_to\_h5py
    \end{itemize}

    \subsubsection{Species}
    Klasa reprezentująca pewną grupę makrocząstek o wspólnych cechach, takich jak ładunek bądź masa.
    Przykładowo, w symulacji oddziaływania lasera z tarczą wodorową jedną grupą są protony, zaś drugą - elektrony.
    Do zainicjalizowania wymaga instancji \code{Grid}, z której pobiera informacje takie jak stałe fizyczne $c$,
    $\varepsilon_0$, liczbę iteracji czasowych $N_T$ i czas trwania iteracji $\Delta t$.

    Zawiera skalary:
    \begin{itemize}
        \item $N$ - liczba makrocząstek
        \item $q$ - ładunek cząstki
        \item $m$ - masa cząstki
        \item \code{scaling} - liczba rzeczywistych cząstek, jakie reprezentuje sobą makrocząstka. Jej sumaryczny ładunek
             wynosi $q * $\code{scaling}, masa $m * $\code{scaling}.
        \item \code{N\_alive} - liczba cząstek obecnie aktywnych w symulacji. Zmniejsza się w miarę usuwania cząstek przez
            warunki brzegowe.
    \end{itemize}

    Poza skalarami zawiera tablice rozmiaru $N$:
    \begin{itemize}
        \item jednowymiarowych położeń makrocząstek $x^n$, zapisywanych w iteracjach $n, n+1, n+2$\ldots
        \item trójwymiarowych prędkości makrocząstek $\vec{v}^{n+\frac{1}{2}}$, zapisywanych w iteracjach $n+\frac{1}{2}, n+{3}{2}, n+{5}{2}$\ldots
        \item stanu makrocząstek (flagi boolowskie oznaczające cząstki aktywne bądź usunięte z obszaru symulacji)
    \end{itemize}

    Poza tym, zawiera też informacje dotyczące zbierania danych diagnostycznych dla cząstek, niepotrzebnych
    bezpośrednio w czasie symulacji:
    \begin{itemize}
        \item \code{name} - słowny identyfikator grupy cząstek, dla potrzeb legend wykresów
        \item $N_T$ - liczbę iteracji czasowych w symulacji
        \item $N_T^s$ - zmniejszoną liczbę iteracji, w których następuje pełne zapisanie położeń i prędkości cząstek.
            Dane te są wykorzystywane do tworzenia diagramów fazowych cząstek.
        \item odpowiadające poprzednio wymienionym tablice rozmiaru $(N_T^s, N)$, $(N_T^s, N, 3)$.
        \item jedną tablicę rozmiaru $(N_T, N_G)$ dotyczącą zebranym podczas depozycji ładunku informacjom diagnostycznym
            o przestrzennej gęstości cząstek.
        \item trzy tablice rozmiaru $(N_T)$ dotyczącą średnich prędkości, średnich kwadratów prędkości i odchyleń
            standardowych prędkości.
    \end{itemize}

    Jeżeli liczba makrocząstek lub iteracji przekracza pewną stałą, dane zapisywane są jedynie dla co $n$-tej cząstki,
    gdzie $n$ jest najniższą liczbą całkowitą która pozwala na zmniejszenie tablic poniżej tej stałej.

    Warto wspomnieć o metodach klasy \code{Species}:
    \begin{itemize}
        \item push \todo{fill these}
    \end{itemize}

    \subsubsection{Simulation}
    Klasa zbierająca w całość Grid oraz dowolną liczbę Species zawartych w symulacji, jak również
    pozwalająca w prosty sposób na wykonywanie iteracji algorytmu i analizy danych. Jest tworzona tak przy
    uruchamianiu symulacji, jak i przy wczytywaniu danych z plików \code{.hdf5}.

    \begin{itemize}
        \item $\Delta t$ - krok czasowy
        \item $N_T$ - liczba iteracji w symulacji
        \item \code{Grid} - obiekt siatki
        \item \code{list\_species} - lista grup makrocząstek w symulacji
    \end{itemize}
    \todo{metody simulation}

    Przygotowanie warunków początkowych do danej symulacji polega na utworzeniu nowej klasy dziedziczącej
    po \code{Simulation}, która przygotowuje siatkę, cząstki i warunki brzegowe zgodnie z założeniami
    eksperymentu i wywołuje konstruktor \code{Simulation}. Należy również przeciążyć metodę \code{grid_species_init},
    która przygotowuje warunki początkowe. Domyślna wersja tej metody wykonuje pierwszą, początkową iterację równań ruchu,
    która pozwala na zachowanie symplektyczności integratora równań ruchu, \todo{stylistyka?}
    co pomaga zachować energię cząstek w symulacji.

    Aby uruchomić symulację, należy wywołać jedną z metod:
    \begin{itemize}
         \item \code{run} - podstawowy cykl obliczeń, używany do pomiarów wydajności programu
         \item \code{test\_run} - obliczenia oraz obróbka danych na potrzeby analizy, głównie stosowana w testach
         \item \code{lazy\_run} - \code{test\_run} z zapisem do pliku oraz wczytaniem z pliku \emph{.hdf5},
             jeżeli początkowe
             warunki oraz wersja kodu zgadzają się. W przeciwnym razie symulacja zostaje uruchomiona na nowo.
    \end{itemize}

    \subsubsection{Pliki pomocnicze}
    Poza powyższymi program jest podzielony na pliki: \todo{aktualizacja}
    \begin{itemize}
        \item algorithms\_grid - zawiera algorytmy dotyczące rozwiązywania równań Maxwella na dyskretnej siatce
        \item algorithms\_interpolation - zawiera algorytmy interpolujące pola z cząstek na siatkę i odwrotnie
        \item algorithms\_pusher - zawiera algorytmy integrujące numerycznie równania ruchu cząstek
        \item animation - tworzy animacje dla celów analizy danych
        \item static\_plots - tworzy statyczne wykresy dla celów analizy danych
        \item plotting - zawiera ustawienia dotyczące analizy danych \todo{czy to można przenieść do simulation czy gdzieś?}
    \end{itemize}

    Przygotowane konfiguracje istniejących symulacji są zawarte w plikach \code{configs/run\_*}: \todo{przeformułować}
    \begin{itemize}
        \item run\_coldplasma
        \item run\_twostream
        \item run\_wave
        \item run\_beam
        \item run\_laser
    \end{itemize}

    Algorytmiczne testy jednostkowe są zawarte w katalogu \code{tests}.

\section[Weryfikacja]{Część weryfikacyjna} % 30-40% - opis wyników, analiza, weryfikacja i porównanie do danych literaturowych
    Niniejsza analiza przeprowadzona została na ``finalnej'' w chwili pisania niniejszej pracy wersji programu.
    W repozytorium Git na Githubie jest to commit ``placeholder'' \todo{uzupełnić commita}
    identyfikowany również jako wersja 1.0.

    \subsection{Przypadki testowe}

    Kod przetestowano w dwojaki sposób. Pierwszym z nich są testy jednostkowe.
    Automatyczne testy jednostkowe uruchamiane po każdej wymiernej zmianie kodu
    pozwalają kontrolować działanie programu znacznie ułatwiają zapobieganie
    błędom.

    Poszczególne algorytmy podlegały testom przy użyciu ogólnodostępnego
    pakietu \code{pytest} \todo{pytest reference.} i większości były
    uruchamiane na platformie TravisCI.

    \subsubsection{Testy algorytmiczne}
    Testy algorytmiczne polegały na przeprowadzeniu fragmentu symulacji - w
    przypadku testów algorytmów było to na przykład wygenerowanie pojedynczej
    cząstki o jednostkowej prędkości oraz zdepozytowanie jej gęstości prądu na
    siatkę, co pozwala porównać otrzymany wynik z przewidywanym analitycznie
    dla danego rozmiaru siatki i położenia cząstki. 
    \todo{sprawdzić listę testów}
    \begin{enumerate}
        \itemi Gather
            \begin{enumerate}
                \item Depozycja prądu z pojedynczej cząstki na niewielką siatkę
                \item Depozycja prądu z dwóch pojedynczych cząstek na niewielką siatkę
                    i porównanie z sumą prądów dla obu pojedynczyczh cząstek
                \item Depozycja prądu z dużej ilości równomiernie rozłożonych cząstek
            \end{enumerate}

        \itemi Solve
            \begin{enumerate}
                \item Symulacja fali sinusoidalnej, obwiedni impulsu i złożenia tych dwóch
                    propagujących się w próżni
            \end{enumerate}

        \itemi Scatter
            \begin{enumerate}
                \item \ldots \todo{write these}
            \end{enumerate}

        \itemi Push
            \begin{enumerate}
                \itemii Ruch w jednorodnym polu elektrycznym wzdłuż osi układu
                \itemii Ruch w jednorodnym polu magnetycznym z polem magnetycznym
            \end{enumerate}
    \end{enumerate}

    \subsubsection{Testy symulacyjne}
    Testy symulacyjne polegały na uruchomieniu niewielkiej symulacji testowej z różnymi warunkami brzegowymi
    i ilościowym, automatycznym zweryfikowaniu dynamiki zjawisk w niej zachodzących.

    Zastosowano kod do symulacji kilku znanych problemów w fizyce plazmy:
    \subsubsection{oscylacje zimnej plazmy}
    Jest to efektywnie fala stojąca. Jednorodne rozmieszczenie cząstek z zerową prędkością początkową (stąd określenie
    "zimna plazma" jako nietermalna)
    \todo{czy ja ruszam prędkości czy położenia i czy to nie powinno zmienić fazy}
    jednego typu na okresowej siatce z jednoczesnym wysunięciem ich z położeń równowagi o $\Delta x = A \sin(kx)$,
    gdzie $k = n 2 \pi / L$, pozwala na obserwację
    oscylacji cząstek wokół ich stabilnych położeń równowagi. W przestrzeni fazowej $x, V_x$ cząstki zataczają efektywnie
    elipsy, co pozwala wnioskować że ruch ten jest harmoniczny.

    Jest to, oczywiście, spełnione jedynie dla niewielkich odchyleń; dla $A \to dx$ \todo{dx}
    obserwuje się nieliniowy reżim \todo{i co}

    Jest to też łoże testowe \todo{sformułowanie}
    dla innych przypadków, takich jak efekt Kaiser-Wilhelm \todo{sformułowanie z BL}
    oraz \todo{czegoś jeszcze.}
    \subsubsection{niestabilność dwóch strumieni} \todo{
    Różnice między tym a poprzednim przypadkiem to obecność dwóch jednorodnie rozłożonych strumieni cząstek
    z przeciwnie skierowanymi prędkościami wzdłuż osi układu.

    Dla niewielkich prędkości \todo{sparametryzować}
    obserwuje się liniowy reżim \todo{bunchingu}

    Dla dużych prędkości \todo{sprawdzić}
     obserwuje się nieliniowe zachowanie cząstek, które zaczynają się mieszać ze sobą, zaś cały układ się termalizuje.
     \todo{opisać dalej}
    \subsection{Symulacja oddziaływania lasera z tarczą wodorową}

    Jako warunki początkowe przyjęto plazmę z liniowo narastającą funkcją rozkładu gęstości (jest to tak zwany obszar prejonizacji) \todo{preplazmy?}

    Gęstość rozkładu plazmy przyjęto jako

    Początkowe prędkości cząstek przyjęto jako zerowe. \todo{wylosowano z relatywistycznego rozkładu Maxwella w kierunkach y, z}

    Za moc lasera przyjęto $10^{23} W/m^2$, \todo{ASK: czy to nie jest za dużo?}
    zaś za jego długość fali 1.064 $\mu$m (jest to laser Nd:YAG)

    Długość obszaru symulacji to \todo{

    Prędkość światła $c$, stałą dielektryczną $\varepsilon_0$, ładunek elementarny $e$, masy protonu i elektronu $m_p$, $m_e$ przyjęto według tablic,
    jak obrazuje następująca tabela:

    \todo{zrobić tabelkę na stałe}

    \subsection{Benchmarki - szybkość, zasobożerność} \todo{fix}
    Do przeprowadzenia testów wydajności kodu użyto \todo{
    \subsection{Problemy napotkane w trakcie pisania kodu}

\section[Zakończenie]{Zakończenie} % 3-5 stron
    Utworzono kod symulacyjny implementacyjny algorytm particle-in-cell w Pythonie przy użyciu wszystkich dostępnych
    możliwości, jakie daje ekosystem open-source. Kod zoptymalizowano przy użyciu % TODO: zoptymalizować.
    Otrzymane wyniki benchmarków pozwalają sądzić, że \todo{dokończyć}

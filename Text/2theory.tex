\section[Część analityczno-teoretyczna]{Część analityczno-teoretyczna} % 30% pracy - opis problematyki podjętego tematu w zakresie wykorzystanym w pracy i analizie

    \subsection{Plazma - czwarty stan materii}

    Plazma, powszechnie nazywana czwartym stanem materii, to zbiór zjonizowanych
    cząstek oraz elektronów przejawiających jako grupa globalną obojętność elektryczną. Innymi słowy, od gazu plazmy
    odróżnia fakt, że cząstki są zjonizowane, więc oddziałują kolektywnie między sobą na odległość,
    ale ich pola elektryczne wzajemnie się neutralizują na długich dystansach.

    Plazmy występują w całym wszechświecie, od materii międzygwiezdnej po błyskawice.
    Ich istnienie uwarunkowane jest obecnością wysokich energii, wystarczających do zjonizowania atomów gazu.

    Fizyka plazmy jest stosunkowo młodą nauką, której rozwój nastąpił dopiero w ostatnim stuleciu, zaczynając od badań
    Langmuira (1928), który eksperymentował z jonizowaniem gazów w szklanych rurach zwanych rurami Crookesa,
    służących do generowania promieniowania katodowego, czyli, jak wiemy obecnie, strumieni elektronów.

    Globalny wzrost zainteresowania fizyką plazmy na arenie geopoliycznej ozpoczął się w latach '50 ubiegłego wieku,
    gdy uświadomiono sobie, że można zastosować ją do przeprowadzania kontrolowanych reakcji syntezy jądrowej, \todo[inline]{TODO: reference: fusion in europe history of fusion}
    które mogą mieć zastosowania w energetyce jako następny etap rozwoju po reakcjach rozpadu wykorzystywanych
    w ``klasycznych'' elektrowniach jądrowych. Był to jeden z elementów zimnowojennego wyścigu technologicznego
    międzu Stanami Zjednoczonymi a ZSRR,
    jak również jeden z projektów mających na celu ponowne nawiązanie współpracy naukowej między supermocarstwami
    po zakończeniu tego konfliktu. \todo[inline]{TODO reference fusion for energy history of fusion}

    Poza tym ogromnym projektem plazmy mają szerokie zastosowania w obecnym przemyśle, na przykład:
    \begin{itemize}
        \item metalurgicznym - cięcie metalu przy użyciu łuków plazmowych
        \item elektronicznym i materiałowym - żłobienie powierzchni urządzeń
            półprzewodnikowych, powierzchniowa obróbka materiałów, depozycja
            aktywnych jonów pod powierzchnią czyszczenie powierzchni, depozycja
            cienkich warstw związków chemicznych na powierzchniach (CVD)
        \item kosmicznym - silniki plazmowe, interakcja z rozgrzanym powietrzem podczas powtórnego wchodzenia
            w atmosferę 
        \item użytkowym - ekrany telewizorów, oświetlenie (świetlówki)
    \end{itemize}

    Należy też zwrócić uwagę, że ze względu na złożoność układów plazmowych
    pra-komputerowa fizyka miała ogromne problemy z merytorycznymi badaniami
    zachowania plazmy poza wybranymi, mocno uproszczonymi reżimami. Postęp w
    badaniach plazmy, jak sugeruje rozwój technologii kontrolowanej syntezy
    jądrowej, jest silnie skorelowany \todo[inline]{ref youtube wykład} z
    rozwojem mocy obliczeniowej oraz algorytmów symulacyjnych.

    \subsection{Modelowanie i symulacja plazmy}

    Zjawiska z zakresu fizyki plazmy są jednymi z bardziej złożonych problemów modelowanie komputerowej.
    Głównym, koncepcyjnie, powodem uniemożliwiającym zastosowanie prostych metod symulacji
    znanych z newtonowskiej dynamiki molekularnej jest mnogość oddziaływań - każda cząstka oddziałuje
    z każdą inną nawzajem poprzez niepomijalne oddziaływania kulombowskie, skalujące się z odległością jak
    $\approx r^{-2}$.

    Z powodu dużej liczby cząstek w układach plazmowych, jedynymi podejściami
    fundamentalnymi (jako opierającymi się na fundamentalnej fizyce) są opisy
    kinetyczne. Wielkością opisującą plazmę jest tu funkcja dystrybucji (zwana
    też funkcją rozkładu) zdefiniowana jako $f_s(\vec{x}, \vec{v}, t) d\vec{x}
    d\vec{v}$ opisująca gęstość rozkładu danej grupy cząstek $s$ plazmy w
    sześciowymiarowej przestrzeni fazowej (po trzy wymiary na położenia oraz
    prędkości). Ewolucja czasowa funkcji rozkładu dokonuje się poprzez
    rozwiązanie wariantu równania Boltzmanna zwanego równaniem Vlasova,
    \todo[inline]{Włazowa?}
    które sprzęga gęstości ładunku i prądu otrzymywane z funkcji dystrybucji
    z równaniami Maxwella na ewolucję pola elektromagnetycznego. Równanie
    Vlasova może zostać rozszerzone do równania Fokkera-Plancka uwzględniającego
    bezpośrednie kolizje międzycząsteczkowe.


    \begin{equation}
        \frac{d} {dt} f_{\alpha} (\vec{x}, \vec{v}, t) - \nabla f - \nabla_{\vec{v}} (\vec{v} \times \vec{B} + \vec{E})= f_{coll}
        \label{eqn:Vlasov}
    \end{equation}
        \todo[inline]{wzór na równanie Vlasova}

    W praktyce równanie Vlasova jest trudne do rozwiązania poza trywialnymi
    przypadkami o ułatwiających problem symetriach.  Jednym z powodów tej
    trudności jest konieczność uzyskania dobrej rozdzielczości prędkości przy
    jednoczesnym zachowaniu zakresów obejmujących prędkości relatywistyczne.
    Jako równanie różniczkowe cząstkowe, równanie Vlasova jest rozwiązywane na
    dyskretnych siatkach, należy zauważyć zaś, należy zauważyć, że skalowanie
    liczby punktów na siatce tego typu jest proporcjonalne do $N_r^3 N_v^3$,
    gdzie $N_r$ to liczba punktów przestrzennych, zaś $N_v$ to liczba punktów
    na siatce prędkości. Jest to więc często niepraktyczne obliczeniowo,
    między innymi ze względu na istotne w plazmach fuzyjnych zjawisko
    ``uciekających elektronów'' o relatywistycznych prędkościach.

    W modelowaniu komputerowym plazmy stosuje się dwa główne podejścia:
    \begin{enumerate}
        \item modele kinetyczne rozwiązujące bezpośrednio równania typu Vlasova na dyskretnych siatkach
        \item modele płynowe oparte na ciągłym opisie plazmy poprzez uśrednienie po dystrybucji
            wielkości termodynamicznych, co daje modele takie jak magnetohydrodynamikę. Jest to wciąż
            układ równań różniczkowych cząstkowych, lecz na mniej wymiarowej siatce. Niestety,
            nie nadają się one do badań plazmy daleko od równowagi z powodu czynionych przy nich
            założeń takich jak maxwellowski rozkład prędkości.
        \item modele dyskretne oparte na samplowaniu dystrybucji plazmy przy użyciu dyskretnych cząstek,
            pozwalające w prosty sposób uzyskać dobre przybliżenie faktycznego ruchu cząstek w plazmie
            i prądów generowanych tym ruchem.
    \end{enumerate}

    Prawdopodobnie najpopularniejszym modelem z tej drugiej kategorii są modele Particle-in-cell.

    \subsection{Modele Particle-in-cell}

    Idea modelu particle-in-cell (\emph{PIC}) jest wyjątkowo prosta i opiera się na idei
    przyspieszenia najbardziej złożonego obliczeniowo kroku symulacji dynamiki
    molekularnej, czyli obliczania sił międzycząsteczkowych. Cząstki poruszają
    się w ciągłej, Lagrange'owskiej przestrzeni.  Ich ruch wykorzystywany jest
    do zebrania informacji dotyczącej gęstości ładunku i prądu na dyskretną,
    Eulerowską siatkę. Na siatce rozwiązane są (jako równania różniczkowe
    cząstkowe) równania Maxwella, dzięki którym otrzymuje się pola elektryczne
    i magnetyczne, które z powrotem są przekazane do położeń cząstek.
    Obliczeniowo, uwzględniając koszty odpowiednich interpolacji, pozwala to
    zredukować złożoność kroku obliczenia sił międzycząsteczkowych do $n
    \log{n}$ z $n^2$ \todo[inline]{wyrazić złożoność PIC przez rozmiar siatki}

    \subsubsection{Pętla obliczeniowa PIC}
    Obliczeniowo algorytm particle-in-cell składa się z czterech elementów powtarzających się cyklicznie:
    \begin{itemize}
        \item Zbierz (Gather)\\
    Depozycja ładunku oraz prądu z położeń cząstek do lokacji na dyskretnej
    siatce poprzez interpolację, co pozwala na sprawne rozwiązanie na tej
    siatce równań Maxwella jako układu różnicowych równań cząstkowych zamiast
    obliczania skalujących się kwadratowo w liczbie cząstek oddziaływań
    kulombowskich między nimi.  W naszym elektromagnetycznym przypadku bardziej
    istotną jest depozycja prądu na siatkę, co szerzej tłumaczy następny
    fragment.
    \item Rozwiąż (Solve)\\
    Sprawne rozwiązanie równań Maxwella na dyskretnej, Eulerowskiej siatce.
    Znalezienie pól elektrycznego i magnetycznego na podstawie gęstości ładunku
    i prądu na siatce.  Istnieją dwie główne szkoły rozwiązywania tych równań:
    metody globalne i lokalne. Metody globalne wykorzystują zazwyczaj równania
    dywergencyjne (prawo Gaussa dla pola elektrycznego)
    \begin{align}
        \rho / \varepsilon_0 = \nabla \cdot \vec{E}
        0 = \nabla \cdot \vec{B}
        \label{divergence-equations}
    \end{align}
    rozwiązywane iteracyjnie (metody takie jak Gaussa-Seidela lub gradientów
    sprzężonych) \todo[inline]{ref} lub spektralnie, przy użyciu transformat
    Fouriera bądź Hankela. \todo[inline]{ref} Metody lokalne z kolei
    wykorzystują równania rotacyjne (prawa Ampera-Maxwella oraz Faradaya)
    \begin{align}
        \nabla \times \vec{E} = -\partial \vec{B} / \partial t
        \nabla \times \vec{B} = \mu_0 \Big( \vec{J} + \varepsilon_0 \partial \vec{E} / \partial t
        \label{rotation-equations}
    \end{align}

    Metody globalne nadają się do modeli elektrostatycznych,
    nierelatywistycznych.  Metody lokalne pozwalają na ograniczenie szybkości
    propagacji zaburzeń do prędkości światła, co przybliża metodę numeryczną do
    fizyki zachodzącej w rzeczywistym układzie tego typu.
    \item Rozprosz (Scatter)
    Interpolacja pól z siatki do lokacji cząstek, co pozwala określić siły
    elektromagnetyczne działające na cząstki.  Należy przy tym zauważyć, że
    jako że interpolacja sił wymaga jedynie lokalnej informacji co do pól
    elektromagnetycznych w okolicy cząstki, ta część algorytmu sprawia, że
    algorytmy Particle-in-cell doskonale nadają się do zrównoleglenia (problem
    jest w bardzo dobrym przybliżeniu ``trywialnie paralelizowalny''). Z tego
    powodu algorytmy Particle-in-cell nadają się doskonale do wykorzystania
    rosnącej mocy kart graficznych i architektur GPGPU.
    \item Porusz (Push)
    iteracja równań ruchu cząstek
    \begin{equation}
        d \vec{p}/dt = \vec{F} = q (\vec{E} + \vec{v} \times \vec{B}
        \label{eq-of-motion}
    \end{equation}

    na podstawie ich prędkości (aktualizacja położeń) oraz działających na nie
    sił elektromagnetycznych (aktualizacja prędkości). Należy zauważyć, że
    modele PIC nie modelują bezpośrednich kolizji między cząstkami - mogą one
    jednak zostać dodane niebezpośrednio, na przykład poprzez metody Monte
    Carlo. \todo[inline]{refka}

    Jako że każda cząstka, zakładając znane pola elektromagnetyczne w jej
    położeniu, porusza się niezależnie, jest to kolejny fragment doskonale
    nadający się do zrównoleglenia.
    \end{itemize}
    \subsubsection{Makrocząstki}
    Należy zauważyć, że obecnie nie jest jeszcze możliwe dokładne odwzorowanie
    dynamiki układów plazmowych w sensie interakcji między poszczególnymi
    cząstkami ze względu na liczbę cząstek rzędu liczby Avogadro $\approx
    10^{23}$.  W tym kontekście bardzo szczęśliwym jest fakt, że wszystkie
    istotne wielkości zależą nie od ładunku ani masy, ale od stosunku $q/m$. W
    praktyce stosuje się więc \emph{makrocząstki}, obdarzone ładunkiem i masą
    będące wielokrotnościami tych wielkości dla cząstek występujących w naturze
    (jak jony i elektrony, pozwalając jednocześnie zachować gęstości cząstek i
    ładunku zbliżone do rzeczywistych.

    W symulacjach elektromagnetycznych zazwyczaj (``tradycyjnie'') stosuje się
    gęstości cząstek (rzeczywistych) rzędu jednej dziesiątej bądź setnej
    gęstości krytycznej plazmy $n_c$, która oznacza taką koncentrację
    elektronów, przy której fala laserowa zaczyna być tłumiona
    zamiast być przepuszczaną przez plazmę.
    \todo[inline]{zweryfikować}

    \begin{equation}
        n_c = m_e \varepsilon_0 * (\frac{2 \pi c}{e \lambda})^2
        \label{eqn:critical-density}
    \end{equation}
    gdzie $m_e$ to masa spoczynkowa elektronu, $\varepsilon_0$ to przenikalność elektryczna próżni, \todo[inline]{przenikalność?}
    $c$ to prędkość światła w próżni, $e$ to ładunek elementarny, zaś $\lambda$ to długość fali.

    Gęstość takiej makrocząstki, oznaczana $n_{pic}$, oznacza innymi słowy liczbę rzeczywistych cząstek, jakie reprezentuje
    sobą jedna makrocząstka. \todo[inline]{To jest generalnie moja własna analiza i nie jestem jej w 100\% pewien, ale tak 80\% to dałbym.}

    \subsection{Problem testowy}

    Problemem testowym, jakiego używamy do przetestowania dokładności i wydajności działania algorytmu jest
    interakcja impulsu laserowego z tarczą składającą się ze zjonizowanego wodoru i elektronów.

    Układ ten modelowany jest jako jednowymiarowy. Jest to tak zwany w literaturze model 1D-3D.
    O ile położenia cząstek są jednowymiarowe ze względu na znaczną symetrię
    cylindryczną układu, cząstki mają prędkości w pełnych trzech wymiarach. Jest to konieczne ze względu
    na oddziaływania cząstek z polem elektromagnetycznym propagującym się wzdłuż osi układu.

    Układ ten jest silnie zbliżony do rzeczywistych eksperymentów prowadzonych w IFPiLM.
    \todo[inline]{Tu bym chciał prosić o weryfikację.}

    \subsection{Python}
    Python jest wysokopoziomowym, interpretowanym językiem programowania, którego atutami są szybkie prototypowanie,

    Python znajduje zastosowania w analizie danych, uczeniu maszynowym (zwłaszcza w astronomii). W zakresie symulacji
    w ostatnich czasach powstały kody skalujące się nawet w zakres superkomputerów, na przykład w mechanice płynów.
    Nie można tu nie wspomnieć o utworzonym ostatnio kodzie \code{PyFR},
    \todo[inline]{refka i opis PyFR}

    Atutem Pythona w wysokowydajnych obliczeniach jest łatwość wywoływania w nim zewnętrznych bibliotek napisanych
    na przykład w C lub Fortranie, co pozwala na osiągnięcie podobnych rezultatów wydajnościowych jak dla kodów
    napisanych w językach niskopoziomowych bez faktycznej pracy z tymi językami. Ostatnimi czasy popularną staje się
    również kompilacja just-in-time wysokopoziomowego kodu Pythona do kodu niskopoziomowego przy pierwszym
    uruchomieniu programu \todo[inline]{numba}

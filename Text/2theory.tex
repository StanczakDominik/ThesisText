\section[Część analityczno-teoretyczna]{Część analityczno-teoretyczna} % 30% pracy - opis problematyki podjętego tematu w zakresie wykorzystanym w pracy i analizie
    Plazma, powszechnie nazywana czwartym stanem materii, to zbiór
    zjonizowanych cząstek oraz elektronów przejawiających jako grupa globalną
    obojętność elektryczną. Innymi słowy, od gazu plazmy odróżnia fakt, że
    cząstki są zjonizowane, więc oddziałują kolektywnie między sobą na
    odległość, ale ich pola elektryczne wzajemnie się neutralizują na długich
    dystansach.

    Plazmy występują w całym wszechświecie, od materii międzygwiezdnej po
    błyskawice.  Ich istnienie uwarunkowane jest obecnością wysokich energii,
    wystarczających do zjonizowania atomów gazu.

    Fizyka plazmy jest stosunkowo młodą nauką, której rozwój nastąpił dopiero w
    ostatnim stuleciu, zaczynając od badań Langmuira (1928), który
    eksperymentował z jonizowaniem gazów w szklanych rurach zwanych rurami
    Crookesa, służących do generowania promieniowania katodowego, czyli, jak
    wiemy obecnie, strumieni elektronów.

    Globalny wzrost zainteresowania fizyką plazmy na arenie geopolitycznej
    rozpoczął się w latach '50 ubiegłego wieku, gdy uświadomiono sobie, że
    można zastosować ją do przeprowadzania kontrolowanych reakcji syntezy
    jądrowej, \todo[inline]{TODO: reference: fusion in europe history of
    fusion} które mogą mieć zastosowania w energetyce jako następny etap
    rozwoju po reakcjach rozpadu wykorzystywanych w ``klasycznych''
    elektrowniach jądrowych. Był to jeden z elementów zimnowojennego wyścigu
    technologicznego między Stanami Zjednoczonymi a ZSRR, jak również jeden z
    projektów mających na celu ponowne nawiązanie współpracy naukowej między
    supermocarstwami po zakończeniu tego konfliktu. \todo[inline]{TODO
    reference piece of the sun} Obecnie trwają intensywne badania nad tym
    problemem, których dotychczasową kulminacją jest budowany we Francji tokamak
    ITER.

    Poza tym ogromnym projektem plazmy mają szerokie zastosowania w obecnym
    przemyśle, na przykład:
    \begin{itemize}
        \item metalurgicznym - cięcie metalu przy użyciu łuków plazmowych
        \item elektronicznym i materiałowym - żłobienie powierzchni urządzeń
            półprzewodnikowych, powierzchniowa obróbka materiałów, depozycja
            aktywnych jonów pod powierzchnią czyszczenie powierzchni, depozycja
            cienkich warstw związków chemicznych na powierzchniach (CVD)
        \item kosmicznym - silniki plazmowe, interakcja z rozgrzanym powietrzem
            podczas powtórnego wchodzenia w atmosferę
        \item użytkowym - ekrany telewizorów, oświetlenie (świetlówki)
    \end{itemize}

    Należy też zwrócić uwagę, że ze względu na złożoność układów plazmowych
    pra-komputerowa fizyka miała ogromne problemy z merytorycznymi badaniami
    zachowania plazmy poza wybranymi, mocno uproszczonymi reżimami. Postęp w
    badaniach plazmy, jak sugeruje rozwój technologii kontrolowanej syntezy
    jądrowej, jest silnie skorelowany \todo[inline]{ref youtube wykład, prezentacja} z
    rozwojem mocy obliczeniowej oraz algorytmów symulacyjnych.

    \subsection{Modelowanie i symulacja plazmy}

    Modelowanie zjawisk z zakresu fizyki plazmy jest jednym z bardziej
    złożonych problemów fizyki komputerowej.  Głównym, koncepcyjnie, powodem
    uniemożliwiającym zastosowanie prostych metod symulacji znanych z
    newtonowskiej dynamiki molekularnej jest mnogość oddziaływań - każda
    cząstka oddziałuje z każdą inną nawzajem poprzez niepomijalne oddziaływania
    kulombowskie, skalujące się z odległością jak
    $\approx r^{-2}$.

    Z powodu dużej liczby cząstek w układach plazmowych, jedynymi podejściami
    fundamentalnymi (jako opierającymi się na fundamentalnej fizyce) są opisy
    kinetyczne. Wielkością opisującą plazmę jest tu funkcja dystrybucji (zwana
    też funkcją rozkładu) zdefiniowana jako $f_s(\vec{x}, \vec{v}, t) d\vec{x}
    d\vec{v}$ opisująca gęstość rozkładu danej grupy cząstek $s$ plazmy w
    sześciowymiarowej przestrzeni fazowej (po trzy wymiary na położenia oraz
    prędkości). Ewolucja czasowa funkcji rozkładu dokonuje się poprzez
    rozwiązanie wariantu równania Boltzmanna zwanego równaniem Vlasova,
    \todo[inline]{Włazowa?}
    które sprzęga gęstości ładunku i prądu otrzymywane z funkcji dystrybucji
    z równaniami Maxwella na ewolucję pola elektromagnetycznego. Równanie
    Vlasova może zostać rozszerzone do równania Fokkera-Plancka uwzględniającego
    bezpośrednie kolizje międzycząsteczkowe.


    \begin{equation}
        \frac{d} {dt} f_{\alpha} (\vec{x}, \vec{v}, t) - \nabla f - \nabla_{\vec{v}} (\vec{v} \times \vec{B} + \vec{E})= f_{coll}
        \label{eqn:Vlasov}
    \end{equation}
        \todo[inline]{wzór na równanie Vlasova}

    W praktyce równanie Vlasova jest trudne do rozwiązania poza trywialnymi
    przypadkami o ułatwiających problem symetriach.  Jednym z powodów tej
    trudności jest konieczność uzyskania dobrej rozdzielczości prędkości przy
    jednoczesnym zachowaniu zakresów obejmujących prędkości relatywistyczne.
    Jako równanie różniczkowe cząstkowe, równanie Vlasova jest rozwiązywane na
    dyskretnych siatkach, należy zauważyć zaś, należy zauważyć, że skalowanie
    liczby punktów na siatce tego typu jest proporcjonalne do $N_r^3 N_v^3$,
    gdzie $N_r$ to liczba punktów przestrzennych, zaś $N_v$ to liczba punktów
    na siatce prędkości. Jest to więc często niepraktyczne obliczeniowo,
    między innymi ze względu na istotne w plazmach fuzyjnych zjawisko
    ``uciekających elektronów'' o relatywistycznych prędkościach.

    W modelowaniu komputerowym plazmy stosuje się trzy główne koncepcyjne podejścia:
    \begin{enumerate}
        \item modele kinetyczne rozwiązujące bezpośrednio równania typu Vlasova
            na dyskretnych siatkach
        \item modele płynowe oparte na ciągłym opisie plazmy poprzez
            uśrednienie po dystrybucji wielkości termodynamicznych, co daje
            modele takie jak magnetohydrodynamikę. Jest to wciąż układ równań
            różniczkowych cząstkowych, lecz na mniej wymiarowej siatce.
            Niestety, nie nadają się one do badań plazmy daleko od równowagi z
            powodu czynionych przy nich założeń takich jak maxwellowski rozkład
            prędkości. Znajdują za to szerokie zastosowanie w astronomii.
        \item modele dyskretne oparte na samplowaniu dystrybucji plazmy przy
            użyciu dyskretnych cząstek, pozwalające w prosty sposób uzyskać
            dobre przybliżenie faktycznego ruchu cząstek w plazmie i prądów
            generowanych tym ruchem.
    \end{enumerate}

    Prawdopodobnie najpopularniejszym modelem z tej trzeciej kategorii są modele
    Particle-in-cell.

    \subsection{Modele Particle-in-cell}

    Idea modelu particle-in-cell (\emph{PIC}) jest wyjątkowo prosta i opiera
    się na idei przyspieszenia najbardziej złożonego obliczeniowo kroku
    symulacji dynamiki molekularnej, czyli obliczania sił międzycząsteczkowych.
    Cząstki poruszają się w ciągłej, Lagrange'owskiej przestrzeni.  Ich ruch
    wykorzystywany jest do zebrania informacji dotyczącej gęstości ładunku i
    prądu na dyskretną, Eulerowską siatkę. Na siatce rozwiązane są (jako
    równania różniczkowe cząstkowe) równania Maxwella, dzięki którym otrzymuje
    się pola elektryczne i magnetyczne, które z powrotem są przekazane do
    położeń cząstek.  Obliczeniowo, uwzględniając koszty odpowiednich
    interpolacji, pozwala to zredukować złożoność kroku obliczenia sił
    międzycząsteczkowych do $n \log{n}$ z $n^2$ \todo[inline]{wyrazić złożoność
    PIC przez rozmiar siatki}

    \subsubsection{Pętla obliczeniowa PIC}
    Obliczeniowo algorytm particle-in-cell składa się z czterech elementów
    powtarzających się cyklicznie:
    \begin{itemize}
        \item Zbierz (Gather)\\
    Depozycja ładunku oraz prądu z położeń cząstek do lokacji na dyskretnej
    siatce poprzez interpolację, co pozwala na sprawne rozwiązanie na tej
    siatce równań Maxwella jako układu różnicowych równań cząstkowych zamiast
    obliczania skalujących się kwadratowo w liczbie cząstek oddziaływań
    kulombowskich między nimi.  W naszym elektromagnetycznym przypadku bardziej
    istotną jest depozycja prądu na siatkę, co szerzej tłumaczy następny
    fragment.
    \item Rozwiąż (Solve)\\
    Sprawne rozwiązanie równań Maxwella na dyskretnej, Eulerowskiej siatce.
    Znalezienie pól elektrycznego i magnetycznego na podstawie gęstości ładunku
    i prądu na siatce.  Istnieją dwie główne szkoły rozwiązywania tych równań:
    metody globalne i lokalne. Metody globalne wykorzystują zazwyczaj równania
    dywergencyjne (prawo Gaussa dla pola elektrycznego)
    \begin{align}
        \rho / \varepsilon_0 = \nabla \cdot \vec{E}
        0 = \nabla \cdot \vec{B}
        \label{divergence-equations}
    \end{align}
    rozwiązywane iteracyjnie (metody takie jak Gaussa-Seidela lub gradientów
    sprzężonych) \todo[inline]{ref} lub spektralnie, przy użyciu transformat
    Fouriera bądź Hankela. \todo[inline]{ref} Metody lokalne z kolei
    wykorzystują równania rotacyjne (prawa Ampera-Maxwella oraz Faradaya)
    \begin{align}
        \nabla \times \vec{E} = -\partial \vec{B} / \partial t
        \nabla \times \vec{B} = \mu_0 \Big( \vec{J} + \varepsilon_0 \partial \vec{E} / \partial t
        \label{rotation-equations}
    \end{align}

    Metody globalne nadają się do modeli elektrostatycznych,
    nierelatywistycznych.  Metody lokalne pozwalają na ograniczenie szybkości
    propagacji zaburzeń do prędkości światła, co przybliża metodę numeryczną do
    fizyki zachodzącej w rzeczywistym układzie tego typu.
    \item Rozprosz (Scatter) \\
    Interpolacja pól z siatki do lokacji cząstek, co pozwala określić siły
    elektromagnetyczne działające na cząstki.  Należy przy tym zauważyć, że
    jako że interpolacja sił wymaga jedynie lokalnej informacji co do pól
    elektromagnetycznych w okolicy cząstki, ta część algorytmu sprawia, że
    algorytmy Particle-in-cell doskonale nadają się do zrównoleglenia (problem
    jest w bardzo dobrym przybliżeniu ``trywialnie paralelizowalny''). Z tego
    powodu algorytmy Particle-in-cell nadają się doskonale do wykorzystania
    rosnącej mocy kart graficznych i architektur GPGPU.
    \item Porusz (Push) \\
    iteracja równań ruchu cząstek
    \begin{equation}
        d \vec{p}/dt = \vec{F} = q (\vec{E} + \vec{v} \times \vec{B}
        \label{eq-of-motion}
    \end{equation}
    na podstawie ich prędkości (aktualizacja położeń) oraz działających na nie
    sił elektromagnetycznych (aktualizacja prędkości). Należy zauważyć, że
    modele PIC nie modelują bezpośrednich kolizji między cząstkami. Kolizje
    mogą jednak zostać dodane niebezpośrednio, na przykład poprzez metody Monte
    Carlo. \todo[inline]{refka}

    Jako że każda cząstka, zakładając znane pola elektromagnetyczne w jej
    położeniu, porusza się niezależnie, jest to kolejny fragment doskonale
    nadający się do zrównoleglenia.
    \end{itemize}
    \subsubsection{Makrocząstki}
    Należy zauważyć, że obecnie nie jest jeszcze możliwe dokładne odwzorowanie
    dynamiki układów plazmowych w sensie interakcji między poszczególnymi
    cząstkami ze względu na liczbę cząstek rzędu liczby Avogadro $\approx
    10^{23}$.  W tym kontekście bardzo szczęśliwym jest fakt, że wszystkie
    istotne wielkości zależą nie od ładunku ani masy, ale od stosunku $q/m$. W
    praktyce stosuje się więc \emph{makrocząstki}, obdarzone ładunkiem i masą
    będące wielokrotnościami tych wielkości dla cząstek występujących w naturze
    (jak jony i elektrony, pozwalając jednocześnie zachować gęstości cząstek i
    ładunku zbliżone do rzeczywistych.

    W symulacjach elektromagnetycznych zazwyczaj (``tradycyjnie'') stosuje się
    gęstości cząstek (rzeczywistych) rzędu jednej dziesiątej bądź setnej
    gęstości krytycznej plazmy $n_c$, która oznacza taką koncentrację
    elektronów, przy której fala laserowa zaczyna być tłumiona zamiast być
    przepuszczaną przez plazmę.  \todo[inline]{zweryfikować}

    \begin{equation}
        n_c = m_e \varepsilon_0 * {(\frac{2 \pi c}{e \lambda})}^2
        \label{eqn:critical-density}
    \end{equation}
    gdzie $m_e$ to masa spoczynkowa elektronu, $\varepsilon_0$ to przenikalność
    elektryczna próżni, $c$ to prędkość światła w
    próżni, $e$ to ładunek elementarny, zaś $\lambda$ to długość fali.

    Gęstość takiej makrocząstki, oznaczana $n_{pic}$, oznacza innymi słowy
    liczbę rzeczywistych cząstek, jakie reprezentuje sobą jedna makrocząstka.
    \todo[inline]{To jest generalnie moja własna analiza i nie jestem jej w
    100\% pewien, ale tak 80\% to dałbym.}

    \subsection{Problem testowy}

    Problemem testowym, jakiego używamy do przetestowania dokładności i
    wydajności działania algorytmu jest interakcja impulsu laserowego z tarczą
    składającą się ze zjonizowanego wodoru i elektronów.

    Układ ten modelowany jest jako jednowymiarowy. Jest to tak zwany w
    literaturze model 1D-3D.  O ile położenia cząstek są jednowymiarowe ze
    względu na znaczną symetrię cylindryczną układu, cząstki mają prędkości w
    pełnych trzech wymiarach. Jest to konieczne ze względu na oddziaływania
    cząstek z polem elektromagnetycznym propagującym się wzdłuż osi układu.

    Układ ten jest silnie zbliżony do rzeczywistych eksperymentów prowadzonych
    w Instytucie Fizyki Plazmy i Laserowej Mikrosyntezy.  \todo[inline]{Tu bym
    chciał prosić o weryfikację.}

    \subsection{Python}
    Python jest wysokopoziomowym, interpretowanym językiem programowania,
    którego atutami są szybkie prototypowanie, bogaty zestaw bibliotek
    numerycznych\todo[inline]{dopisać zalety}

    Python znajduje zastosowania w analizie danych, uczeniu maszynowym
    (zwłaszcza w astronomii). W zakresie symulacji w ostatnich czasach powstały
    kody skalujące się nawet w zakres superkomputerów, na przykład w mechanice
    płynów.  Nie można tu nie wspomnieć o utworzonym niedawno hydrodynamicznym kodzie
    PyFR, łączącym szybkie obliczenia w CUDA C i FORTRANie \todo[inline]{sprawdzić czy fortran}
    z wysokopoziomowością Pythona. Uruchomiono go na klastrze \todo[inline]{klaster}
    i udowodniono jego skalowanie do poziomów \todo[inline]{obejrzeć tamtą prezentację}
    \todo[inline]{refka i opis PyFR}

    Atutem Pythona w wysokowydajnych obliczeniach jest łatwość wywoływania w
    nim zewnętrznych bibliotek napisanych na przykład w C lub Fortranie, co
    pozwala na osiągnięcie podobnych rezultatów wydajnościowych jak dla kodów
    napisanych w językach niskopoziomowych bez faktycznej pracy z tymi
    językami.



    \subsubsection{Numpy}
    \code{numpy} to biblioteka umożliwiająca wykonywanie złożonych obliczeń na
    n-wymiarowych macierzach bądź tablicach, utworzona w celu umożlwiienia
    zastąpienia operacjami wektorowymi iteracji po tablicach, powszechnie
    stosowanych w metodach numerycznych i będących znanym słabym punktem
    Pythona.
    \todo[inline]{REFERENCE źródło na powolność pętli}

    Pod zewnętrzną powłoką zawiera odwołania do znanych, wypróbowanych i
    sprawdzonych w numeryce modułów \code{LAPACK}, \code{BLAS} napisanych w
    szybkich, niskopoziomowych językach C oraz \code{FORTRAN}.  Jest to
    \emph{de facto} standard większości obliczeń numerycznych w Pythonie.

    Należy zauważyć, że operacje matematyczne w \code{Numpy} są automatycznie
    zrównoleglane \todo[inline]{refka intel MKL} tam, gdzie pozwala na to
    niezależność obliczeń.

    Numpy jest oprogramowaniem otwartym, udostępnianym na licencji BSD.
    \todo[inline]{refka}

    \subsubsection{scipy}
    Kolejną podstawową biblioteką w numerycznym Pythonie jest \code{scipy},
    biblioteka zawierająca wydajne implementacje wielu podstawowych algorytmów
    numerycznych służących między innymi całkowaniu, optymalizacji, algebrze
    liniowej czy transformatom Fouriera.  W naszym przypadku stosujemy zawarte
    w tej bibliotece funkcje całkujące do określenia początkowego profilu
    gęstości plazmy.  \todo[inline]{czy stosuję scipy gdzieś jeszcze}

    \subsubsection{Numba}
    \code{numba} to biblioteka służąca do kompilacji just-in-time wysokopoziomowego
    kodu Pythona do kodu niskopoziomowego przy pierwszym uruchomieniu programu. W
    wielu przypadkach pozwala na osiągnięcie kodem napisanym w czystym Pythonie
    wydajności marginalnie niższej bądź nawet równej do analogicznego programu w C
    bądź Fortranie. \todo[inline]{refka} Jednocześnie należy zaznaczyć prostotę jej
    użycia:

    \todo[inline]{fragment kodu. @jit przed kodem}

    Istniejącym od niedawna kodem implementującym tą metodę jest FBPIC
    \todo[inline]{refka}

    \subsubsection{HDF5}
    HDF5 jest wysokowydajnym formatem plikow służącym przechowywaniu danych
    liczbowych w drzewiastej, skompresowanej strukturze danych, razem z
    równoległym, wielowątkowym zapisem tych danych.  W Pythonie implementuje go
    biblioteka h5py. \todo[inline]{reference h5py} Używa się go na przykład w
    \todo[inline]{lista miejsc gdzie używają hdf5}
    \todo[inline]{https://github.com/PPPLDeepLearning/plasma-python}

    W bieżącej pracy wykorzystuje się go do przechowywania danych numerycznych
    dotyczących przebiegu symulacji, pozwalających na ich dalsze przetwarzanie
    i analizę poprzez wizualizację.

    \subsubsection{matplotlib}
    Do wizualizacji danych z symulacji (oraz tworzenia schematów w sekcji
    teoretycznej niniejszej pracy) użyto własnoręcznie napisanych skryptów w
    uniwersalnej bibliotece graficznej \code{matplotlib}. \code{matplotlib}
    zapewnie wsparcia zarówno dla grafik statycznych w różnych układach
    współrzędnych (w tym 3D), jak również dla dynamicznie generowanych animacji
    przedstawiających przebiegi czasowe symulacji.

    Matplotlib również jest oprogramowaniem otwartym, udostępnianym na licencji
    \todo[inline]{matplotlib license, reference}

    \subsubsection{py.test}
    Przy pracy nad kodem użyto frameworku testowego \code{py.test}
    \todo[inline]{refenrece} Obsługa testów jest trywialna:

    \todo[inline]{przykład testu z programu}

    Należy zaznaczyć, że w numeryce, gdzie błędne działanie programu nie
    objawia się zazwyczaj błędem wykonywania programu, a jedynie błędnymi
    wynikami, dobrze zautomatyzowane testy jednostkowe potrafią zaoszczędzić
    bardzo dużo czasu na debugowaniu poprzez automatyzację uruchamiania
    kolejnych partii kodu i lokalizację błędnie działających części algorytmu.
    Dobrze napisane testy są praktycznie koniecznością w dzisiejszych czasach,
    zaś każdy nowo powstały projekt numeryczno-symulacyjny powinien je
    wykorzystywać, najlepiej do weryfikacji każdej części algorytmu z osobna.

    Dobrym przykładem skutecznego testu jednostkowego jest porównanie wyników z
    fragmentu algorytmu (na przykład depozycji ładunku, który to test zawarty
    jest w pliku) \code{pythonpic/tests/test\_current\_deposition.py}
    \todo[inline]{sprawdzić urla} z wynikami z poprzedniego, zweryfikowanego
    programu, bądź z obliczeniem ręcznym.

    \code{py.test} jest oprogramowaniem otwartym, dostępnym na licencji
    \todo[inline]{sprawdzić licencję}

    \subsubsection{Travis CI}
    Nieocenionym narzędziem w pracy nad kodem był system ciągłej integracji
    (\emph{continuous integration}) Travis CI \todo[inline]{refka} dostępny za
    darmo dla projektów open-source. Travis pobiera aktualne wersje kodu przy
    każdej aktualizacji wersji dostępnej na serwerze GitHub i uruchamia testy,
    zwracając komunikat o ewentualnym niepowodzeniu i pozwalając na jednoczesne
    uruchamianie bieżących, intensywnych symulacji przy jednoczesnym
    uruchamianiu lżejszych, acz wciąż zasobożernych \todo[inline]{to słowo}
    symulacji testowych i testów algorytmicznych.

    \subsubsection{snakeviz}

    W optymalizacji przydatny okazał się program \code{snakeviz} dostępny na
    licencji opensource i pozwalający na wizualizację wyników z profilowania
    symulacji. Pozwala w wygodny sposób zbadać, które fragmenty kodu najbardziej
    spowalniają symulację, które są najlepszymi kandydatami do optymalizacji, oraz
    jak skuteczne (bądź nieskuteczne) okazują się próby polepszenia ich wydajności.
    \todo[inline]{refka} \todo[inline]{grafika snakeviz}
